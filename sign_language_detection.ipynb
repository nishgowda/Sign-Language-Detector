{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sign_language_detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMNSXD7Lu2gPb+YBeqbcujS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nishgowda/Sign-Language-Detector/blob/master/sign_language_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wb93ooKuw4GM"
      },
      "source": [
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iDlVGL69keP"
      },
      "source": [
        "*We use this alphabet dictionary to check the output more easily since we can just see the actual letter instead of the numeric label representation.*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlTilomw9cXt"
      },
      "source": [
        "signs = {'0': 'A', '1': 'B', '2': 'C', '3': 'D', '4': 'E', '5': 'F', \n",
        "         '6': 'G', '7': 'H', '8': 'I', '10': 'K', '11': 'L', '12': 'M', \n",
        "         '13': 'N', '14': 'O', '15': 'P', '16': 'Q', '17': 'R', '18': 'S', \n",
        "         '19': 'T', '20': 'U', '21': 'V', '22': 'W', '23': 'X', '24': 'Y' }"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRaHGFttxLWs"
      },
      "source": [
        "# use the standard mnist sign language translation testing and training data\n",
        "class SignsLanguageDataset(Dataset):\n",
        "    def __init__(self, train = True, transform = None):\n",
        "        self.train = train\n",
        "        self.transform = transform\n",
        "  \n",
        "        if self.train == True:\n",
        "            self.signs_lang_dataset = pd.read_csv(\"/content/sign_mnist_test.csv\")\n",
        "        else:\n",
        "            self.signs_lang_dataset = pd.read_csv(\"/content/sign_mnist_train.csv\")\n",
        "            \n",
        "        self.X_set = self.signs_lang_dataset.iloc[:, 1:].values\n",
        "        self.y_set = self.signs_lang_dataset.iloc[:, 0].values\n",
        "        \n",
        "        self.X_set = np.reshape(self.X_set, (self.X_set.shape[0], 1, 28, 28)) / 255\n",
        "        self.y_set = np.array(self.y_set)\n",
        "            \n",
        "    def __getitem__(self, index):\n",
        "        image = self.X_set[index, :, :]\n",
        "        label = self.y_set[index]\n",
        "        sample = {'image_sign': image, 'label': label}\n",
        "        return sample\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.X_set.__len__()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jF1SJM4G-L6C"
      },
      "source": [
        "*Here we use a standard Convolutional Neural Network with\n",
        "2 conv layers and 2 max pools as well as two functions\n",
        "**test** and **evaulate**, which are for generating feedback on the\n",
        "performance of the net.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5J0VWJu9WWe"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 80, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(80, 80, kernel_size=5)\n",
        "\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "        self.batch_norm1 = nn.BatchNorm2d(80)\n",
        "        self.batch_norm2 = nn.BatchNorm2d(80)\n",
        "\n",
        "        self.fc1 = nn.Linear(1280, 250)\n",
        "        self.fc2 = nn.Linear(250, 25)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.batch_norm1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.batch_norm2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "        \n",
        "        return x\n",
        "    \n",
        "    def test(self, predictions, labels):\n",
        "        self.eval()\n",
        "        correct = 0\n",
        "        for p, l in zip(predictions, labels):\n",
        "            if p == l:\n",
        "                correct += 1\n",
        "        \n",
        "        accuracy = correct / len(predictions)\n",
        "        print(\"Correct predictions: %5d / %5d (%5f)\" % (correct, len(predictions), accuracy))\n",
        "        \n",
        "    def evaluate(self, predictions, labels):\n",
        "        correct = 0\n",
        "        for p, l in zip(predictions, labels):\n",
        "            if p == l:\n",
        "                correct += 1\n",
        "        \n",
        "        accuracy = correct / len(predictions)\n",
        "        return(accuracy)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LT3oWO2pxNLI"
      },
      "source": [
        "def train(model, optimizer, epoch, device, train_loader, log_interval):\n",
        "    model.train()\n",
        "\n",
        "    for batch_idx, data in enumerate(train_loader):\n",
        "        img = data['image_sign']\n",
        "        img = img.type(torch.FloatTensor).to(device)\n",
        "        \n",
        "        target = data['label']\n",
        "        target = target.type(torch.LongTensor).to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(img)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(img), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tx0sbccaxQ2b"
      },
      "source": [
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    \n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, data in enumerate(test_loader):\n",
        "            img = data['image_sign']\n",
        "            img = img.type(torch.FloatTensor).to(device)\n",
        "            target = data['label']\n",
        "            target = target.type(torch.LongTensor).to(device)\n",
        "            \n",
        "            output = model(img)\n",
        "            test_loss += F.nll_loss(output, target).item() # sum up batch loss\n",
        "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cC005eM2-q0K"
      },
      "source": [
        "## **Training and Model Validation**\n",
        "Train and test our network with the MNIST Sign Language Dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgpJ-3Rm_o-j",
        "outputId": "4a299b3e-7137-41e5-a8da-39bc53d99963"
      },
      "source": [
        "model = CNN()\n",
        "print(model)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNN(\n",
            "  (conv1): Conv2d(1, 80, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(80, 80, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (batch_norm1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (batch_norm2): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (fc1): Linear(in_features=1280, out_features=250, bias=True)\n",
            "  (fc2): Linear(in_features=250, out_features=25, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVnivmHO_llo"
      },
      "source": [
        "batch_size_train = 5\n",
        "batch_size_test = 4\n",
        "\n",
        "dataset_train = SignsLanguageDataset(train=True)\n",
        "dataset_test = SignsLanguageDataset(train=False)\n",
        "train_loader = DataLoader(dataset=dataset_train, batch_size=batch_size_train)\n",
        "test_loader = DataLoader(dataset=dataset_test, batch_size=batch_size_test)\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "learning_rate = 0.001\n",
        "num_epochs = 7\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.2, weight_decay=0.002)\n",
        "log_interval = 27455\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    train(model, optimizer, epoch, device, train_loader, log_interval)\n",
        "    test(model, device, test_loader)\n",
        "\n",
        "model_name = \"sign_language.pt\"\n",
        "\n",
        "model_path = f\"models/{model_name}\"\n",
        "torch.save(model.state_dict(), model_path)\n",
        "print(f\"Saved model to {model_path}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}